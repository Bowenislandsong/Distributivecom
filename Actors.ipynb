{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote functions in Ray should be thought of as functional and side-effect free. Restricting ourselves only to remote functions gives us distributed functional programming, which is great for many use cases, but in practice is a bit limited.\n",
    "\n",
    "Ray extends the dataflow model with **actors**. An actor is essentially a stateful worker (or a service). When a new actor is instantiated, a new worker is created, and methods of the actor are scheduled on that specific worker and can access and mutate the state of that worker.\n",
    "\n",
    "Suppose we've already started Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for redis server at 127.0.0.1:13780 to respond...\n",
      "Waiting for redis server at 127.0.0.1:53685 to respond...\n",
      "Starting local scheduler with 8 CPUs, 2 GPUs\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8899/notebooks/ray_ui94901.ipynb?token=43ce6bf00ee9e01cff70531c6f9913ae83278889a3bca875\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler97556861'],\n",
       " 'node_ip_address': '127.0.0.1',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store59937875', manager_name='/tmp/plasma_manager40408261', manager_port=51499)],\n",
       " 'redis_address': '127.0.0.1:13780',\n",
       " 'webui_url': 'http://localhost:8899/notebooks/ray_ui94901.ipynb?token=43ce6bf00ee9e01cff70531c6f9913ae83278889a3bca875'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(num_gpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and creating an actor\n",
    "\n",
    "Consider the following simple example. The ray.remote decorator indicates that instances of the Counter class will be actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        \n",
    "    def increment(self):\n",
    "        self.value += 1\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually create an actor, we can instantiate this class by calling Counter.remote ( )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = Counter.remote()\n",
    "a2 = Counter.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an actor is instantiated, the following events happen. \n",
    "\n",
    "1. A node in the cluster is chosen and a worker process is created on that node (by the local scheduler on that node) for the purpose of running methods called on the actor.\n",
    "\n",
    "2. A Counter object is created on that worker and the Counter constructor is run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an actor\n",
    "\n",
    "We can schedule tasks on the actor by calling its methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectID(772c834522eca9c2deb148db93e5e1a5112f338b)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.increment.remote()  # ray.get returns 1\n",
    "a2.increment.remote()  # ray.get returns 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a1.increment.remote() is called, the following events happens.\n",
    "\n",
    "1. A task is created.\n",
    "\n",
    "2. The task is assigned directly to the local scheduler responsible for the actor by the driver's local scheduler. Thus, this scheduling procedure bypasses the global scheduler.\n",
    "\n",
    "3. An object ID is returned. \n",
    "\n",
    "We can then call ray.get on the object ID to retrieve the actual value. \n",
    "\n",
    "Similarly, the call to a2.increment.remote() generates a task that is scheduled on the second Counter actor. Since these two tasks run on different actors, they can be executed in **parallel** (note that only actor methods will be scheduled on actor workers, regular remote functions will not be).\n",
    "\n",
    "On the other hand, methods called on the same Counter actor are executed **serially** in the order that they are called. They can thus share state with one another, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# Create ten Counter actors.\n",
    "counters = [Counter.remote() for _ in range(10)]\n",
    "\n",
    "# Increment each Counter once and get the results. These tasks all happen\n",
    "# in PARALLEL.\n",
    "results = ray.get([c.increment.remote() for c in counters])\n",
    "print(results)  # prints [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Increment the first Counter five times. These tasks are executed SERIALLY\n",
    "# and share state. \n",
    "results = ray.get([counters[0].increment.remote() for _ in range(5)])\n",
    "print(results)  # prints [2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Interesting Actor Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern is to use actors to encapsulate the mutable state managed by an external library or service.\n",
    "\n",
    "Gym provides an interface to a number of simulated environments for testing and training reinforcement learning agents. These simulators are stateful, and tasks that use these simulators must mutate their state. We can use actors to encapsulate the state of these simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "@ray.remote\n",
    "class GymEnvironment(object):\n",
    "    def __init__(self, name):\n",
    "        self.env = gym.make(name)\n",
    "        self.env.reset()\n",
    "        \n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then instantiate an actor and schedule a task on that actor as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectID(0351eea3b2ccae196709cf18a7593ad663d08206)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong = GymEnvironment.remote(\"Pong-v0\")\n",
    "pong.step.remote(0)  # Take action 0 in the simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPUs on actors\n",
    "\n",
    "A common use case is for an actor to contain a neural network. For example, suppose we have imported Tensorflow and have created a method for constructing a neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def construct_network():\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y),\n",
    "                                                  reduction_indices=[1]))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize\n",
    "    (cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return x, y_, train_step, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define an actor for this network as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define an actor that runs on GPUs. If there are no GPUs, then simply use\n",
    "# ray.remote without any arguments and no parentheses.\n",
    "@ray.remote(num_gpus=1)\n",
    "\n",
    "class NeuralNetOnGPU(object):\n",
    "    def __init__(self):\n",
    "        # Set an environment variable to tell TensorFlow which GPUs to use.\n",
    "        # Note that this must be done before the call to tf.Session.\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(i) for i in \n",
    "                                                       ray.get_gpu_ids()])\n",
    "        with tf.Graph().as_default():\n",
    "            with tf.device(\"/gpu:0\"):\n",
    "                self.x, self.y_, self.train_step, self.accuray = construct\n",
    "                _network()\n",
    "                # Allow this to run on CPUs if there aren't any GPUs\n",
    "                self.sess = tf.Session(config=config)\n",
    "                # Initialize the network.\n",
    "                init = tf.global_variables_initializer()\n",
    "                self.sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To indicate that an actor requires one GPU, we pass in num_gpus=1 to ray.remote. Note that in order for this to work, Ray must have been started with some GPUs, e.g., via ray.init(num_gpus=2). Otherwise, when you try to instantiate the GPU version with NeuralNetOnGPU.remote(), an exception will be thrown saying that there aren’t enough GPUs in the system.\n",
    "\n",
    "When the actor is created, it will have access to a list of the IDs of the GPUs that it is allowed to use via ray. get_gpu_ids(). This is a list of integers, like [], or [1], or [2, 5, 6]. Since we passed in ray. remote(num_gpus=1), this list will have length one.\n",
    "\n",
    "We can put this all together as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for redis server at 127.0.0.1:64838 to respond...\n",
      "Waiting for redis server at 127.0.0.1:57864 to respond...\n",
      "Starting local scheduler with 8 CPUs, 8 GPUs\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8899/notebooks/ray_ui94728.ipynb?token=cd8f3a92fa1a63e4f515d83df6e8ea3bb55d3acd130cc55d\n",
      "======================================================================\n",
      "\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING: Serializing objects of type <class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'> by expanding them as dictionaries of their fields. This behavior may be incorrect in some cases.\n",
      "WARNING: Serializing objects of type <class 'tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet'> by expanding them as dictionaries of their fields. This behavior may be incorrect in some cases.\n",
      "Accuracy is 0.8928999900817871.\n"
     ]
    }
   ],
   "source": [
    "# Restart the kernel before running this to initialize Ray with specified\n",
    "# number of GPUs.\n",
    "import os\n",
    "import ray\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "ray.init(num_gpus=8)\n",
    "def construct_network():\n",
    "    x = tf.placeholder(tf.float32, [None, 784]) \n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return x, y_, train_step, accuracy\n",
    "@ray.remote(num_gpus=1)\n",
    "class NeuralNetOnGPU(object):\n",
    "    def __init__(self, mnist_data):\n",
    "        self.mnist = mnist_data\n",
    "        # Set an environment variable to tell TensorFlow which GPUs to use. Note\n",
    "        # that this must be done before the call to tf.Session. \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(i) for i in \n",
    "                                                       ray.get_gpu_ids()])\n",
    "        \n",
    "        with tf.Graph().as_default(): \n",
    "            with tf.device(\"/gpu:0\"):\n",
    "                # Allow this to run on CPUs if there aren't any GPUs.\n",
    "                self.x, self.y_, self.train_step, self.accuracy = construct_network() \n",
    "                config = tf.ConfigProto(allow_soft_placement=True)\n",
    "                self.sess = tf.Session(config=config)\n",
    "                # Initialize the network.\n",
    "                init = tf.global_variables_initializer()\n",
    "                self.sess.run(init)\n",
    "    def train(self, num_steps): \n",
    "        for _ in range(num_steps):\n",
    "            batch_xs, batch_ys = self.mnist.train.next_batch(100)\n",
    "            self.sess.run(self.train_step, feed_dict={self.x: batch_xs, self.y_: batch_ys})\n",
    "    def get_accuracy(self):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.x: self.mnist.test.images,\n",
    "                                                       self.y_: self.mnist.test.labels})\n",
    "# Load the MNIST dataset and tell Ray how to serialize the custom classes.\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True) # Create the actor.\n",
    "nn = NeuralNetOnGPU.remote(mnist)\n",
    "# Run a few steps of training and print the accuracy.\n",
    "nn.train.remote(100)\n",
    "accuracy = ray.get(nn.get_accuracy.remote()) \n",
    "print(\"Accuracy is {}.\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
